[32m[0328 16:27:39 @logger.py:90][0m Argv: FasterRCNN/train.py
[32m[0328 16:27:40 @train.py:465][0m Environment Information:
--------------------  -----------------------------------------------------------
Python                3.5.3 (default, Sep 27 2018, 17:25:39) [GCC 6.3.0 20170516]
Tensorpack            v0.9.3-2-g2b4ec72e-dirty
TensorFlow            1.13.1/b'v1.13.1-0-g6612da8'
TF Compiler Version   4.8.4
TF CUDA support       True
TF MKL support        False
Nvidia Driver         /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.410.72
CUDA                  /usr/local/cuda-10.0/lib64/libcudart.so.10.0.130
CUDNN                 /usr/local/cuda-10.0/lib64/libcudnn.so.7.4.1
NCCL                  /usr/local/nccl2/lib/libnccl.so.2.3.4
CUDA_VISIBLE_DEVICES  None
GPU 0                 Tesla V100-SXM2-16GB
horovod               0.16.0
cv2                   4.0.0
msgpack               0.6.1
python-prctl          False
--------------------  -----------------------------------------------------------
[32m[0328 16:27:41 @config.py:281][0m Config: ------------------------------------------
{'BACKBONE': {'FREEZE_AFFINE': False,
              'FREEZE_AT': 2,
              'NORM': 'FreezeBN',
              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],
              'STRIDE_1X1': False,
              'TF_PAD_MODE': False,
              'WEIGHTS': 'models/ImageNet-R50-AlignPadding.npz'},
 'CASCADE': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0],
                                  [30.0, 30.0, 15.0, 15.0]],
             'IOUS': [0.5, 0.6, 0.7]},
 'DATA': {'ABSOLUTE_COORD': True,
          'BASEDIR': 'Datasets/',
          'CLASS_NAMES': ['BG', '0', '1', '6', '3', '4', '5', '.', '7', '2', '9', '8', '3$', '"'],
          'DATAFRAME': 'data/frcnn_df.h5',
          'NUM_CATEGORY': 13,
          'NUM_CLASS': 14,
          'TEST': ('test',),
          'TRAIN': ('train', 'val'),
          'VAL': ('test',)},
 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),
         'CASCADE': False,
         'FRCNN_CONV_HEAD_DIM': 256,
         'FRCNN_FC_HEAD_DIM': 1024,
         'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',
         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',
         'NORM': 'None',
         'NUM_CHANNEL': 256,
         'PROPOSAL_MODE': 'Level',
         'RESOLUTION_REQUIREMENT': 32},
 'FRCNN': {'BATCH_PER_IM': 512,
           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],
           'FG_RATIO': 0.25,
           'FG_THRESH': 0.5},
 'MODE_FPN': True,
 'MODE_MASK': False,
 'MRCNN': {'HEAD_DIM': 256},
 'PREPROC': {'MAX_SIZE': 1024.0,
             'PIXEL_MEAN': [123.675, 116.28, 103.53],
             'PIXEL_STD': [58.395, 57.12, 57.375],
             'TEST_SHORT_EDGE_SIZE': 600,
             'TRAIN_SHORT_EDGE_SIZE': [600, 600]},
 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),
         'ANCHOR_SIZES': (32, 64, 128, 256, 512),
         'ANCHOR_STRIDE': 16,
         'BATCH_PER_IM': 256,
         'CROWD_OVERLAP_THRESH': 9.99,
         'FG_RATIO': 0.5,
         'HEAD_DIM': 1024,
         'MIN_SIZE': 0,
         'NEGATIVE_ANCHOR_THRESH': 0.3,
         'NUM_ANCHOR': 15,
         'POSITIVE_ANCHOR_THRESH': 0.7,
         'PROPOSAL_NMS_THRESH': 0.7,
         'TEST_PER_LEVEL_NMS_TOPK': 1000,
         'TEST_POST_NMS_TOPK': 1000,
         'TEST_PRE_NMS_TOPK': 6000,
         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,
         'TRAIN_POST_NMS_TOPK': 2000,
         'TRAIN_PRE_NMS_TOPK': 12000},
 'TEST': {'FRCNN_NMS_THRESH': 0.5,
          'RESULTS_PER_IM': 100,
          'RESULT_SCORE_THRESH': 0.05,
          'RESULT_SCORE_THRESH_VIS': 0.5},
 'TRAIN': {'BASE_LR': 0.01,
           'EVAL_PERIOD': 5,
           'LR_SCHEDULE': [240000, 320000, 360000],
           'NUM_GPUS': 1,
           'STARTING_EPOCH': 1,
           'STEPS_PER_EPOCH': 500,
           'WARMUP': 1000,
           'WARMUP_INIT_LR': 0.0033000000000000004,
           'WEIGHT_DECAY': 0.0001},
 'TRAINER': 'replicated'}
[32m[0328 16:27:41 @train.py:481][0m Warm Up Schedule (steps, value): [(0, 0.0033000000000000004), (1000, 0.01)]
[32m[0328 16:27:41 @train.py:482][0m LR Schedule (epochs, value): [(2, 0.01), (3840.0, 0.001), (5120.0, 0.00010000000000000002)]
[32m[0328 16:27:42 @data.py:50][0m Ground-Truth Boxes:
[36m| class   |   #box |
|:--------|-------:|
| BG      |      0 |
| 0       |   1649 |
| 1       |    497 |
| 6       |    259 |
| 3       |    258 |
| 4       |    269 |
| 5       |    246 |
| .       |    499 |
| 7       |    202 |
| 2       |    354 |
| 9       |    160 |
| 8       |    192 |
| 3$      |      0 |
| "       |      1 |
| total   |   4586 |[0m
[32m[0328 16:27:42 @data.py:295][0m Filtered 0 images which contain no non-crowd groudtruth boxes. Total #images for training: 903
[32m[0328 16:27:42 @train.py:486][0m Total passes of the training set is: 3189.4
[32m[0328 16:27:43 @input_source.py:222][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 16:27:43 @training.py:110][0m Building graph for training tower 0 on device /gpu:0 ...
[32m[0328 16:27:43 @registry.py:126][0m conv0 input: [1, 3, None, None]
[32m[0328 16:27:43 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m conv0 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m pool0 input: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:134][0m pool0 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block0/conv1 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block0/conv1 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block0/conv2 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block0/conv2 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block0/conv3 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block0/conv3 output: [1, 256, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block0/convshortcut input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block0/convshortcut output: [1, 256, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block1/conv1 input: [1, 256, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block1/conv1 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block1/conv2 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block1/conv2 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block1/conv3 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block1/conv3 output: [1, 256, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block2/conv1 input: [1, 256, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block2/conv1 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block2/conv2 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block2/conv2 output: [1, 64, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group0/block2/conv3 input: [1, 64, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group0/block2/conv3 output: [1, 256, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block0/conv1 input: [1, 256, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block0/conv1 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block0/conv2 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block0/conv2 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block0/conv3 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block0/conv3 output: [1, 512, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block0/convshortcut input: [1, 256, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block0/convshortcut output: [1, 512, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block1/conv1 input: [1, 512, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block1/conv1 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block1/conv2 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block1/conv2 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block1/conv3 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block1/conv3 output: [1, 512, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block2/conv1 input: [1, 512, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block2/conv1 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block2/conv2 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block2/conv2 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block2/conv3 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block2/conv3 output: [1, 512, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block3/conv1 input: [1, 512, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block3/conv1 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block3/conv2 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block3/conv2 output: [1, 128, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group1/block3/conv3 input: [1, 128, None, None]
[32m[0328 16:27:44 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:44 @registry.py:134][0m group1/block3/conv3 output: [1, 512, None, None]
[32m[0328 16:27:44 @registry.py:126][0m group2/block0/conv1 input: [1, 512, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block0/conv1 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block0/conv2 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block0/conv2 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block0/conv3 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block0/conv3 output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block0/convshortcut input: [1, 512, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block0/convshortcut output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block1/conv1 input: [1, 1024, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block1/conv1 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block1/conv2 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block1/conv2 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block1/conv3 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block1/conv3 output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block2/conv1 input: [1, 1024, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block2/conv1 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block2/conv2 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block2/conv2 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block2/conv3 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block2/conv3 output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block3/conv1 input: [1, 1024, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block3/conv1 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block3/conv2 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block3/conv2 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block3/conv3 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block3/conv3 output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block4/conv1 input: [1, 1024, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block4/conv1 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block4/conv2 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block4/conv2 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block4/conv3 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block4/conv3 output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block5/conv1 input: [1, 1024, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block5/conv1 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block5/conv2 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block5/conv2 output: [1, 256, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group2/block5/conv3 input: [1, 256, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:45 @registry.py:134][0m group2/block5/conv3 output: [1, 1024, None, None]
[32m[0328 16:27:45 @registry.py:126][0m group3/block0/conv1 input: [1, 1024, None, None]
[32m[0328 16:27:45 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block0/conv1 output: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block0/conv2 input: [1, 512, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block0/conv2 output: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block0/conv3 input: [1, 512, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block0/conv3 output: [1, 2048, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block0/convshortcut input: [1, 1024, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block0/convshortcut output: [1, 2048, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block1/conv1 input: [1, 2048, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block1/conv1 output: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block1/conv2 input: [1, 512, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block1/conv2 output: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block1/conv3 input: [1, 512, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block1/conv3 output: [1, 2048, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block2/conv1 input: [1, 2048, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block2/conv1 output: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block2/conv2 input: [1, 512, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block2/conv2 output: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:126][0m group3/block2/conv3 input: [1, 512, None, None]
[32m[0328 16:27:46 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 16:27:46 @registry.py:134][0m group3/block2/conv3 output: [1, 2048, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn input: [1, 256, None, None],[1, 512, None, None],[1, 1024, None, None],[1, 2048, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/lateral_1x1_c2 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/lateral_1x1_c2 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/lateral_1x1_c3 input: [1, 512, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/lateral_1x1_c3 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/lateral_1x1_c4 input: [1, 1024, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/lateral_1x1_c4 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/lateral_1x1_c5 input: [1, 2048, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/lateral_1x1_c5 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/upsample_lat5 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/upsample_lat5 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/upsample_lat4 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/upsample_lat4 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/upsample_lat3 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/upsample_lat3 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/posthoc_3x3_p2 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/posthoc_3x3_p2 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/posthoc_3x3_p3 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/posthoc_3x3_p3 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/posthoc_3x3_p4 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/posthoc_3x3_p4 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/posthoc_3x3_p5 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/posthoc_3x3_p5 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m fpn/maxpool_p6 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn/maxpool_p6 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m fpn output: [1, 256, None, None],[1, 256, None, None],[1, 256, None, None],[1, 256, None, None],[1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m rpn input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m rpn/conv0 input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m rpn/conv0 output: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:126][0m rpn/class input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m rpn/class output: [1, 3, None, None]
[32m[0328 16:27:46 @registry.py:126][0m rpn/box input: [1, 256, None, None]
[32m[0328 16:27:46 @registry.py:134][0m rpn/box output: [1, 12, None, None]
[32m[0328 16:27:46 @registry.py:134][0m rpn output: [None, None, 3],[None, None, 3, 4]
[32m[0328 16:27:50 @registry.py:126][0m fastrcnn input: [None, 256, 7, 7]
[32m[0328 16:27:50 @registry.py:126][0m fastrcnn/fc6 input: [None, 256, 7, 7]
[32m[0328 16:27:50 @registry.py:134][0m fastrcnn/fc6 output: [None, 1024]
[32m[0328 16:27:50 @registry.py:126][0m fastrcnn/fc7 input: [None, 1024]
[32m[0328 16:27:50 @registry.py:134][0m fastrcnn/fc7 output: [None, 1024]
[32m[0328 16:27:50 @registry.py:134][0m fastrcnn output: [None, 1024]
[32m[0328 16:27:50 @registry.py:126][0m fastrcnn/outputs input: [None, 1024]
[32m[0328 16:27:50 @registry.py:126][0m fastrcnn/outputs/class input: [None, 1024]
[32m[0328 16:27:50 @registry.py:134][0m fastrcnn/outputs/class output: [None, 14]
[32m[0328 16:27:50 @registry.py:126][0m fastrcnn/outputs/box input: [None, 1024]
[32m[0328 16:27:50 @registry.py:134][0m fastrcnn/outputs/box output: [None, 56]
[32m[0328 16:27:50 @registry.py:134][0m fastrcnn/outputs output: [None, 14],[None, 14, 4]
[32m[0328 16:27:51 @regularize.py:97][0m regularize_cost() found 57 variables to regularize.
[32m[0328 16:27:51 @regularize.py:21][0m The following tensors will be regularized: group1/block0/conv1/W:0, group1/block0/conv2/W:0, group1/block0/conv3/W:0, group1/block0/convshortcut/W:0, group1/block1/conv1/W:0, group1/block1/conv2/W:0, group1/block1/conv3/W:0, group1/block2/conv1/W:0, group1/block2/conv2/W:0, group1/block2/conv3/W:0, group1/block3/conv1/W:0, group1/block3/conv2/W:0, group1/block3/conv3/W:0, group2/block0/conv1/W:0, group2/block0/conv2/W:0, group2/block0/conv3/W:0, group2/block0/convshortcut/W:0, group2/block1/conv1/W:0, group2/block1/conv2/W:0, group2/block1/conv3/W:0, group2/block2/conv1/W:0, group2/block2/conv2/W:0, group2/block2/conv3/W:0, group2/block3/conv1/W:0, group2/block3/conv2/W:0, group2/block3/conv3/W:0, group2/block4/conv1/W:0, group2/block4/conv2/W:0, group2/block4/conv3/W:0, group2/block5/conv1/W:0, group2/block5/conv2/W:0, group2/block5/conv3/W:0, group3/block0/conv1/W:0, group3/block0/conv2/W:0, group3/block0/conv3/W:0, group3/block0/convshortcut/W:0, group3/block1/conv1/W:0, group3/block1/conv2/W:0, group3/block1/conv3/W:0, group3/block2/conv1/W:0, group3/block2/conv2/W:0, group3/block2/conv3/W:0, fpn/lateral_1x1_c2/W:0, fpn/lateral_1x1_c3/W:0, fpn/lateral_1x1_c4/W:0, fpn/lateral_1x1_c5/W:0, fpn/posthoc_3x3_p2/W:0, fpn/posthoc_3x3_p3/W:0, fpn/posthoc_3x3_p4/W:0, fpn/posthoc_3x3_p5/W:0, rpn/conv0/W:0, rpn/class/W:0, rpn/box/W:0, fastrcnn/fc6/W:0, fastrcnn/fc7/W:0, fastrcnn/outputs/class/W:0, fastrcnn/outputs/box/W:0
[32m[0328 16:27:58 @training.py:348][0m 'sync_variables_from_main_tower' includes 0 operations.
[32m[0328 16:27:58 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname                                   shape                 #elements
-------------------------------------  ------------------  -----------
group1/block0/conv1/W:0                [1, 1, 256, 128]          32768
group1/block0/conv1/bn/gamma:0         [128]                       128
group1/block0/conv1/bn/beta:0          [128]                       128
group1/block0/conv2/W:0                [3, 3, 128, 128]         147456
group1/block0/conv2/bn/gamma:0         [128]                       128
group1/block0/conv2/bn/beta:0          [128]                       128
group1/block0/conv3/W:0                [1, 1, 128, 512]          65536
group1/block0/conv3/bn/gamma:0         [512]                       512
group1/block0/conv3/bn/beta:0          [512]                       512
group1/block0/convshortcut/W:0         [1, 1, 256, 512]         131072
group1/block0/convshortcut/bn/gamma:0  [512]                       512
group1/block0/convshortcut/bn/beta:0   [512]                       512
group1/block1/conv1/W:0                [1, 1, 512, 128]          65536
group1/block1/conv1/bn/gamma:0         [128]                       128
group1/block1/conv1/bn/beta:0          [128]                       128
group1/block1/conv2/W:0                [3, 3, 128, 128]         147456
group1/block1/conv2/bn/gamma:0         [128]                       128
group1/block1/conv2/bn/beta:0          [128]                       128
group1/block1/conv3/W:0                [1, 1, 128, 512]          65536
group1/block1/conv3/bn/gamma:0         [512]                       512
group1/block1/conv3/bn/beta:0          [512]                       512
group1/block2/conv1/W:0                [1, 1, 512, 128]          65536
group1/block2/conv1/bn/gamma:0         [128]                       128
group1/block2/conv1/bn/beta:0          [128]                       128
group1/block2/conv2/W:0                [3, 3, 128, 128]         147456
group1/block2/conv2/bn/gamma:0         [128]                       128
group1/block2/conv2/bn/beta:0          [128]                       128
group1/block2/conv3/W:0                [1, 1, 128, 512]          65536
group1/block2/conv3/bn/gamma:0         [512]                       512
group1/block2/conv3/bn/beta:0          [512]                       512
group1/block3/conv1/W:0                [1, 1, 512, 128]          65536
group1/block3/conv1/bn/gamma:0         [128]                       128
group1/block3/conv1/bn/beta:0          [128]                       128
group1/block3/conv2/W:0                [3, 3, 128, 128]         147456
group1/block3/conv2/bn/gamma:0         [128]                       128
group1/block3/conv2/bn/beta:0          [128]                       128
group1/block3/conv3/W:0                [1, 1, 128, 512]          65536
group1/block3/conv3/bn/gamma:0         [512]                       512
group1/block3/conv3/bn/beta:0          [512]                       512
group2/block0/conv1/W:0                [1, 1, 512, 256]         131072
group2/block0/conv1/bn/gamma:0         [256]                       256
group2/block0/conv1/bn/beta:0          [256]                       256
group2/block0/conv2/W:0                [3, 3, 256, 256]         589824
group2/block0/conv2/bn/gamma:0         [256]                       256
group2/block0/conv2/bn/beta:0          [256]                       256
group2/block0/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block0/conv3/bn/gamma:0         [1024]                     1024
group2/block0/conv3/bn/beta:0          [1024]                     1024
group2/block0/convshortcut/W:0         [1, 1, 512, 1024]        524288
group2/block0/convshortcut/bn/gamma:0  [1024]                     1024
group2/block0/convshortcut/bn/beta:0   [1024]                     1024
group2/block1/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block1/conv1/bn/gamma:0         [256]                       256
group2/block1/conv1/bn/beta:0          [256]                       256
group2/block1/conv2/W:0                [3, 3, 256, 256]         589824
group2/block1/conv2/bn/gamma:0         [256]                       256
group2/block1/conv2/bn/beta:0          [256]                       256
group2/block1/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block1/conv3/bn/gamma:0         [1024]                     1024
group2/block1/conv3/bn/beta:0          [1024]                     1024
group2/block2/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block2/conv1/bn/gamma:0         [256]                       256
group2/block2/conv1/bn/beta:0          [256]                       256
group2/block2/conv2/W:0                [3, 3, 256, 256]         589824
group2/block2/conv2/bn/gamma:0         [256]                       256
group2/block2/conv2/bn/beta:0          [256]                       256
group2/block2/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block2/conv3/bn/gamma:0         [1024]                     1024
group2/block2/conv3/bn/beta:0          [1024]                     1024
group2/block3/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block3/conv1/bn/gamma:0         [256]                       256
group2/block3/conv1/bn/beta:0          [256]                       256
group2/block3/conv2/W:0                [3, 3, 256, 256]         589824
group2/block3/conv2/bn/gamma:0         [256]                       256
group2/block3/conv2/bn/beta:0          [256]                       256
group2/block3/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block3/conv3/bn/gamma:0         [1024]                     1024
group2/block3/conv3/bn/beta:0          [1024]                     1024
group2/block4/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block4/conv1/bn/gamma:0         [256]                       256
group2/block4/conv1/bn/beta:0          [256]                       256
group2/block4/conv2/W:0                [3, 3, 256, 256]         589824
group2/block4/conv2/bn/gamma:0         [256]                       256
group2/block4/conv2/bn/beta:0          [256]                       256
group2/block4/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block4/conv3/bn/gamma:0         [1024]                     1024
group2/block4/conv3/bn/beta:0          [1024]                     1024
group2/block5/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block5/conv1/bn/gamma:0         [256]                       256
group2/block5/conv1/bn/beta:0          [256]                       256
group2/block5/conv2/W:0                [3, 3, 256, 256]         589824
group2/block5/conv2/bn/gamma:0         [256]                       256
group2/block5/conv2/bn/beta:0          [256]                       256
group2/block5/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block5/conv3/bn/gamma:0         [1024]                     1024
group2/block5/conv3/bn/beta:0          [1024]                     1024
group3/block0/conv1/W:0                [1, 1, 1024, 512]        524288
group3/block0/conv1/bn/gamma:0         [512]                       512
group3/block0/conv1/bn/beta:0          [512]                       512
group3/block0/conv2/W:0                [3, 3, 512, 512]        2359296
group3/block0/conv2/bn/gamma:0         [512]                       512
group3/block0/conv2/bn/beta:0          [512]                       512
group3/block0/conv3/W:0                [1, 1, 512, 2048]       1048576
group3/block0/conv3/bn/gamma:0         [2048]                     2048
group3/block0/conv3/bn/beta:0          [2048]                     2048
group3/block0/convshortcut/W:0         [1, 1, 1024, 2048]      2097152
group3/block0/convshortcut/bn/gamma:0  [2048]                     2048
group3/block0/convshortcut/bn/beta:0   [2048]                     2048
group3/block1/conv1/W:0                [1, 1, 2048, 512]       1048576
group3/block1/conv1/bn/gamma:0         [512]                       512
group3/block1/conv1/bn/beta:0          [512]                       512
group3/block1/conv2/W:0                [3, 3, 512, 512]        2359296
group3/block1/conv2/bn/gamma:0         [512]                       512
group3/block1/conv2/bn/beta:0          [512]                       512
group3/block1/conv3/W:0                [1, 1, 512, 2048]       1048576
group3/block1/conv3/bn/gamma:0         [2048]                     2048
group3/block1/conv3/bn/beta:0          [2048]                     2048
group3/block2/conv1/W:0                [1, 1, 2048, 512]       1048576
group3/block2/conv1/bn/gamma:0         [512]                       512
group3/block2/conv1/bn/beta:0          [512]                       512
group3/block2/conv2/W:0                [3, 3, 512, 512]        2359296
group3/block2/conv2/bn/gamma:0         [512]                       512
group3/block2/conv2/bn/beta:0          [512]                       512
group3/block2/conv3/W:0                [1, 1, 512, 2048]       1048576
group3/block2/conv3/bn/gamma:0         [2048]                     2048
group3/block2/conv3/bn/beta:0          [2048]                     2048
fpn/lateral_1x1_c2/W:0                 [1, 1, 256, 256]          65536
fpn/lateral_1x1_c2/b:0                 [256]                       256
fpn/lateral_1x1_c3/W:0                 [1, 1, 512, 256]         131072
fpn/lateral_1x1_c3/b:0                 [256]                       256
fpn/lateral_1x1_c4/W:0                 [1, 1, 1024, 256]        262144
fpn/lateral_1x1_c4/b:0                 [256]                       256
fpn/lateral_1x1_c5/W:0                 [1, 1, 2048, 256]        524288
fpn/lateral_1x1_c5/b:0                 [256]                       256
fpn/posthoc_3x3_p2/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p2/b:0                 [256]                       256
fpn/posthoc_3x3_p3/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p3/b:0                 [256]                       256
fpn/posthoc_3x3_p4/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p4/b:0                 [256]                       256
fpn/posthoc_3x3_p5/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p5/b:0                 [256]                       256
rpn/conv0/W:0                          [3, 3, 256, 256]         589824
rpn/conv0/b:0                          [256]                       256
rpn/class/W:0                          [1, 1, 256, 3]              768
rpn/class/b:0                          [3]                           3
rpn/box/W:0                            [1, 1, 256, 12]            3072
rpn/box/b:0                            [12]                         12
fastrcnn/fc6/W:0                       [12544, 1024]          12845056
fastrcnn/fc6/b:0                       [1024]                     1024
fastrcnn/fc7/W:0                       [1024, 1024]            1048576
fastrcnn/fc7/b:0                       [1024]                     1024
fastrcnn/outputs/class/W:0             [1024, 14]                14336
fastrcnn/outputs/class/b:0             [14]                         14
fastrcnn/outputs/box/W:0               [1024, 56]                57344
fastrcnn/outputs/box/b:0               [56]                         56[36m
Number of trainable variables: 156
Number of parameters (elements): 41188437
Storage space needed for all trainable variables: 157.12MB[0m
[32m[0328 16:27:58 @base.py:209][0m Setup callbacks graph ...
[32m[0328 16:27:58 @argtools.py:146][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
[32m[0328 16:28:06 @tower.py:140][0m Building graph for predict tower 'tower-pred-0' on device /gpu:0 ...
[32m[0328 16:28:08 @collection.py:152][0m Size of these collections were changed in tower-pred-0: (tf.GraphKeys.MODEL_VARIABLES: 183->238)
[32m[0328 16:28:08 @summary.py:46][0m [MovingAverageSummary] 69 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.
[32m[0328 16:28:08 @summary.py:93][0m Summarizing collection 'summaries' of size 71.
[32m[0328 16:28:11 @base.py:230][0m Creating the session ...
[32m[0328 16:28:19 @base.py:236][0m Initializing the session ...
[32m[0328 16:28:19 @sessinit.py:205][0m Variables to restore from dict: group3/block2/conv3/bn/mean/EMA:0, group2/block1/conv1/bn/gamma:0, group2/block0/conv2/W:0, group3/block1/conv3/W:0, group2/block2/conv3/bn/mean/EMA:0, group0/block1/conv1/bn/gamma:0, group3/block0/conv1/bn/variance/EMA:0, group2/block3/conv3/bn/gamma:0, group2/block5/conv1/bn/beta:0, group2/block3/conv2/bn/variance/EMA:0, group3/block2/conv3/bn/variance/EMA:0, group0/block2/conv2/bn/mean/EMA:0, group1/block2/conv3/bn/mean/EMA:0, group2/block5/conv2/W:0, group2/block2/conv1/bn/gamma:0, group2/block4/conv1/bn/beta:0, group2/block0/conv3/bn/mean/EMA:0, group2/block4/conv2/bn/variance/EMA:0, group0/block1/conv3/bn/variance/EMA:0, group3/block0/conv3/W:0, group0/block0/conv1/bn/gamma:0, group2/block3/conv2/W:0, group1/block0/convshortcut/bn/beta:0, conv0/bn/variance/EMA:0, group1/block2/conv3/bn/gamma:0, group1/block3/conv2/W:0, group2/block3/conv1/bn/variance/EMA:0, group2/block0/convshortcut/bn/beta:0, group0/block0/conv1/W:0, group2/block5/conv3/bn/variance/EMA:0, group3/block1/conv1/bn/gamma:0, group1/block3/conv1/bn/gamma:0, group2/block4/conv2/bn/beta:0, conv0/bn/beta:0, group1/block1/conv3/W:0, group2/block1/conv2/bn/beta:0, group0/block2/conv3/bn/gamma:0, group2/block5/conv1/bn/gamma:0, group2/block3/conv1/W:0, group2/block3/conv3/W:0, group2/block2/conv3/bn/variance/EMA:0, group0/block0/conv2/W:0, group2/block2/conv3/bn/beta:0, group2/block0/convshortcut/bn/variance/EMA:0, group3/block0/conv3/bn/beta:0, group1/block2/conv2/W:0, group2/block1/conv2/W:0, group1/block2/conv3/W:0, group0/block2/conv2/bn/variance/EMA:0, group0/block0/conv2/bn/mean/EMA:0, group3/block2/conv3/bn/beta:0, group0/block2/conv3/bn/beta:0, group1/block0/conv3/bn/gamma:0, group1/block3/conv2/bn/mean/EMA:0, group0/block1/conv1/bn/variance/EMA:0, group1/block0/conv3/bn/variance/EMA:0, group2/block2/conv2/bn/gamma:0, group1/block2/conv2/bn/gamma:0, group3/block0/conv3/bn/variance/EMA:0, group3/block2/conv1/bn/variance/EMA:0, group1/block3/conv3/W:0, group0/block1/conv1/bn/beta:0, group0/block1/conv2/W:0, group1/block3/conv1/bn/variance/EMA:0, group1/block3/conv3/bn/beta:0, group3/block2/conv3/bn/gamma:0, group2/block0/conv1/bn/beta:0, group0/block2/conv3/bn/mean/EMA:0, group3/block2/conv2/bn/mean/EMA:0, group2/block5/conv2/bn/beta:0, group3/block1/conv3/bn/variance/EMA:0, group1/block3/conv1/W:0, group2/block1/conv1/W:0, group3/block1/conv3/bn/gamma:0, group2/block4/conv3/W:0, group1/block0/convshortcut/bn/variance/EMA:0, group2/block1/conv1/bn/mean/EMA:0, group1/block3/conv2/bn/gamma:0, group2/block3/conv2/bn/mean/EMA:0, group3/block1/conv2/bn/mean/EMA:0, group3/block2/conv2/bn/gamma:0, group0/block0/convshortcut/bn/mean/EMA:0, group0/block2/conv1/W:0, group3/block0/conv3/bn/gamma:0, group1/block3/conv3/bn/mean/EMA:0, group2/block1/conv1/bn/variance/EMA:0, group2/block1/conv2/bn/gamma:0, group3/block1/conv1/bn/variance/EMA:0, group0/block2/conv1/bn/gamma:0, group0/block0/conv2/bn/variance/EMA:0, group2/block0/convshortcut/bn/gamma:0, group2/block0/conv3/bn/variance/EMA:0, group1/block0/conv1/W:0, group2/block3/conv1/bn/gamma:0, group1/block3/conv1/bn/beta:0, group1/block3/conv3/bn/gamma:0, group2/block3/conv1/bn/beta:0, group1/block1/conv2/W:0, group2/block3/conv3/bn/beta:0, group3/block0/convshortcut/bn/beta:0, group0/block1/conv3/bn/gamma:0, group0/block0/convshortcut/bn/variance/EMA:0, group0/block0/conv3/bn/mean/EMA:0, group3/block0/conv2/bn/variance/EMA:0, group1/block0/conv2/bn/mean/EMA:0, group3/block0/convshortcut/bn/variance/EMA:0, group0/block2/conv2/bn/gamma:0, group3/block1/conv1/bn/beta:0, group3/block0/conv3/bn/mean/EMA:0, group1/block3/conv2/bn/variance/EMA:0, group2/block4/conv1/W:0, group0/block1/conv3/W:0, group1/block0/conv3/W:0, group0/block0/conv2/bn/gamma:0, group2/block4/conv2/W:0, group0/block0/conv3/bn/beta:0, group3/block0/conv1/bn/beta:0, group1/block2/conv2/bn/variance/EMA:0, group1/block1/conv1/bn/gamma:0, group2/block0/conv1/bn/gamma:0, group1/block1/conv2/bn/mean/EMA:0, group0/block2/conv3/bn/variance/EMA:0, group2/block4/conv3/bn/beta:0, group2/block0/conv2/bn/beta:0, group2/block5/conv3/W:0, group1/block2/conv1/bn/variance/EMA:0, group2/block2/conv1/bn/beta:0, group2/block5/conv2/bn/gamma:0, group3/block2/conv1/bn/beta:0, group3/block2/conv1/bn/gamma:0, group1/block2/conv3/bn/variance/EMA:0, group2/block2/conv2/W:0, group0/block0/conv3/bn/variance/EMA:0, group3/block2/conv1/bn/mean/EMA:0, group1/block2/conv2/bn/beta:0, group1/block0/convshortcut/bn/gamma:0, group1/block0/conv1/bn/beta:0, group2/block0/conv3/bn/gamma:0, group1/block0/conv3/bn/mean/EMA:0, group0/block0/conv3/W:0, group2/block0/conv1/bn/variance/EMA:0, group2/block4/conv3/bn/variance/EMA:0, group3/block0/conv1/W:0, group0/block1/conv1/W:0, group0/block1/conv2/bn/gamma:0, group2/block2/conv2/bn/beta:0, group3/block1/conv2/bn/beta:0, group3/block1/conv2/bn/gamma:0, group0/block0/conv1/bn/variance/EMA:0, group3/block1/conv1/bn/mean/EMA:0, group3/block0/conv2/bn/beta:0, group2/block4/conv1/bn/variance/EMA:0, group0/block0/convshortcut/W:0, group2/block3/conv3/bn/mean/EMA:0, group1/block0/conv1/bn/gamma:0, group2/block1/conv3/W:0, group2/block1/conv2/bn/mean/EMA:0, group2/block1/conv3/bn/gamma:0, group3/block2/conv2/W:0, group2/block3/conv2/bn/gamma:0, group2/block0/conv2/bn/gamma:0, group1/block1/conv3/bn/variance/EMA:0, group2/block2/conv3/bn/gamma:0, group1/block1/conv2/bn/variance/EMA:0, group3/block0/convshortcut/bn/mean/EMA:0, group1/block3/conv1/bn/mean/EMA:0, group3/block0/conv1/bn/mean/EMA:0, group0/block1/conv3/bn/mean/EMA:0, group1/block0/conv1/bn/mean/EMA:0, group3/block1/conv1/W:0, group1/block1/conv2/bn/beta:0, group1/block0/conv2/bn/variance/EMA:0, group1/block0/convshortcut/bn/mean/EMA:0, group2/block5/conv2/bn/mean/EMA:0, group2/block4/conv1/bn/gamma:0, group2/block0/conv1/bn/mean/EMA:0, group2/block5/conv3/bn/gamma:0, group1/block3/conv3/bn/variance/EMA:0, group2/block2/conv2/bn/variance/EMA:0, group1/block2/conv3/bn/beta:0, group2/block2/conv1/bn/variance/EMA:0, group3/block2/conv2/bn/beta:0, group0/block2/conv2/bn/beta:0, group3/block0/convshortcut/bn/gamma:0, group0/block2/conv1/bn/beta:0, group2/block0/conv3/W:0, group1/block1/conv3/bn/beta:0, group0/block0/convshortcut/bn/gamma:0, group2/block5/conv2/bn/variance/EMA:0, group2/block2/conv3/W:0, group1/block0/conv2/bn/gamma:0, group3/block0/conv2/bn/gamma:0, group1/block1/conv1/bn/mean/EMA:0, group2/block0/convshortcut/bn/mean/EMA:0, group3/block2/conv1/W:0, conv0/bn/mean/EMA:0, group2/block0/conv3/bn/beta:0, group2/block1/conv2/bn/variance/EMA:0, group1/block0/conv2/bn/beta:0, group1/block2/conv1/bn/beta:0, group2/block4/conv3/bn/mean/EMA:0, group1/block1/conv2/bn/gamma:0, group1/block1/conv3/bn/gamma:0, group1/block0/conv3/bn/beta:0, group2/block4/conv2/bn/gamma:0, group2/block4/conv3/bn/gamma:0, group1/block1/conv1/bn/variance/EMA:0, conv0/bn/gamma:0, group0/block2/conv3/W:0, group0/block0/convshortcut/bn/beta:0, group0/block1/conv1/bn/mean/EMA:0, group3/block0/convshortcut/W:0, group0/block0/conv3/bn/gamma:0, group1/block1/conv3/bn/mean/EMA:0, group1/block0/conv1/bn/variance/EMA:0, group0/block1/conv2/bn/variance/EMA:0, group3/block1/conv3/bn/beta:0, group1/block1/conv1/W:0, group1/block3/conv2/bn/beta:0, conv0/W:0, group3/block0/conv2/bn/mean/EMA:0, group0/block1/conv2/bn/mean/EMA:0, group2/block0/conv1/W:0, group3/block2/conv2/bn/variance/EMA:0, group1/block0/conv2/W:0, group0/block2/conv1/bn/mean/EMA:0, group2/block5/conv3/bn/mean/EMA:0, group1/block2/conv2/bn/mean/EMA:0, group3/block1/conv3/bn/mean/EMA:0, group2/block1/conv1/bn/beta:0, group3/block0/conv2/W:0, group2/block0/conv2/bn/variance/EMA:0, group3/block1/conv2/bn/variance/EMA:0, group2/block3/conv3/bn/variance/EMA:0, group3/block0/conv1/bn/gamma:0, group2/block4/conv2/bn/mean/EMA:0, group0/block0/conv2/bn/beta:0, group2/block5/conv1/bn/variance/EMA:0, group2/block1/conv3/bn/variance/EMA:0, group3/block2/conv3/W:0, group1/block1/conv1/bn/beta:0, group0/block1/conv2/bn/beta:0, group2/block5/conv3/bn/beta:0, group2/block0/convshortcut/W:0, group2/block2/conv2/bn/mean/EMA:0, group2/block2/conv1/bn/mean/EMA:0, group1/block2/conv1/bn/mean/EMA:0, group0/block2/conv1/bn/variance/EMA:0, group1/block2/conv1/W:0, group0/block0/conv1/bn/mean/EMA:0, group0/block1/conv3/bn/beta:0, group2/block5/conv1/W:0, group0/block2/conv2/W:0, group2/block3/conv2/bn/beta:0, group1/block2/conv1/bn/gamma:0, group2/block1/conv3/bn/mean/EMA:0, group1/block0/convshortcut/W:0, group2/block5/conv1/bn/mean/EMA:0, group3/block1/conv2/W:0, group0/block0/conv1/bn/beta:0, group2/block2/conv1/W:0, group2/block4/conv1/bn/mean/EMA:0, group2/block0/conv2/bn/mean/EMA:0, group2/block3/conv1/bn/mean/EMA:0, group2/block1/conv3/bn/beta:0
[32m[0328 16:28:19 @sessinit.py:87][0m [5m[31mWRN[0m The following variables are in the graph, but not found in the dict: fastrcnn/fc6/W, fastrcnn/fc6/b, fastrcnn/fc7/W, fastrcnn/fc7/b, fastrcnn/outputs/box/W, fastrcnn/outputs/box/b, fastrcnn/outputs/class/W, fastrcnn/outputs/class/b, fpn/lateral_1x1_c2/W, fpn/lateral_1x1_c2/b, fpn/lateral_1x1_c3/W, fpn/lateral_1x1_c3/b, fpn/lateral_1x1_c4/W, fpn/lateral_1x1_c4/b, fpn/lateral_1x1_c5/W, fpn/lateral_1x1_c5/b, fpn/posthoc_3x3_p2/W, fpn/posthoc_3x3_p2/b, fpn/posthoc_3x3_p3/W, fpn/posthoc_3x3_p3/b, fpn/posthoc_3x3_p4/W, fpn/posthoc_3x3_p4/b, fpn/posthoc_3x3_p5/W, fpn/posthoc_3x3_p5/b, global_step, learning_rate, rpn/box/W, rpn/box/b, rpn/class/W, rpn/class/b, rpn/conv0/W, rpn/conv0/b
[32m[0328 16:28:19 @sessinit.py:87][0m [5m[31mWRN[0m The following variables are in the dict, but not found in the graph: linear/W, linear/b
[32m[0328 16:28:19 @sessinit.py:218][0m Restoring 265 variables from dict ...
[32m[0328 16:28:19 @base.py:243][0m Graph Finalized.
[32m[0328 16:28:19 @concurrency.py:38][0m Starting EnqueueThread QueueInput/input_queue ...
[32m[0328 16:28:19 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:28:22 @param.py:158][0m [HyperParamSetter] At global_step=0, learning_rate is set to 0.003300
[32m[0328 16:28:22 @eval.py:222][0m [EvalCallback] Will evaluate every 5 epochs
[32m[0328 16:28:23 @base.py:275][0m Start Epoch 1 ...
[32m[0328 16:28:39 @param.py:161][0m [HyperParamSetter] At global_step=1, learning_rate changes from 0.003300 to 0.003307
[32m[0328 16:29:53 @base.py:285][0m Epoch 1 (global_step 500) finished, time:1 minute 30 seconds.
[32m[0328 16:29:53 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:29:53 @misc.py:109][0m Estimated Time Left: 6 days 1 hour 52 minutes 26 seconds
[32m[0328 16:29:53 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:29:53 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:29:53 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.27827
[32m[0328 16:29:53 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.41666
[32m[0328 16:29:53 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.88429
[32m[0328 16:29:53 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.45928
[32m[0328 16:29:53 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.26469
[32m[0328 16:29:53 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 69.8
[32m[0328 16:29:53 @monitor.py:467][0m learning_rate: 0.0066433
[32m[0328 16:29:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 308.2
[32m[0328 16:29:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 144.62
[32m[0328 16:29:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 55.918
[32m[0328 16:29:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.2595
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/box_loss: 0.021431
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/label_loss: 0.042105
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0039753
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.012154
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.31752
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.40837
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.66663
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.67667
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.67215
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.63863
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 2.1927
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 188.29
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0071658
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.012613
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.40113
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.46248
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.53029
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.7615
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.7558
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.7275
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 6.3212
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 48.896
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.0073823
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.0098433
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.59917
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.63672
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.68624
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.82201
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.82146
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.80896
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 7.0319
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 15.234
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.0029077
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.0074881
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.35648
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.4313
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.59512
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.60949
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.60949
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.50468
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 2.269
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 3.5663
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_loss: 6.9808e-06
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49414
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49951
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:29:53 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.011725
[32m[0328 16:29:53 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 442.2
[32m[0328 16:29:53 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 69.8
[32m[0328 16:29:53 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.73947
[32m[0328 16:29:53 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 0.99988
[32m[0328 16:29:53 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.99373
[32m[0328 16:29:53 @monitor.py:467][0m total_cost: 1.2288
[32m[0328 16:29:53 @monitor.py:467][0m wd_cost: 0.47033
[32m[0328 16:29:53 @base.py:275][0m Start Epoch 2 ...
[32m[0328 16:29:54 @param.py:161][0m [HyperParamSetter] At global_step=501, learning_rate changes from 0.006650 to 0.006657
[32m[0328 16:30:53 @base.py:285][0m Epoch 2 (global_step 1000) finished, time:59.1 seconds.
[32m[0328 16:30:53 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:30:53 @param.py:158][0m [HyperParamSetter] At global_step=1000, learning_rate is set to 0.010000
[32m[0328 16:30:53 @misc.py:109][0m Estimated Time Left: 5 days 12 minutes 22 seconds
[32m[0328 16:30:53 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:30:53 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:30:53 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.15884
[32m[0328 16:30:53 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.22085
[32m[0328 16:30:53 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.92772
[32m[0328 16:30:53 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.17892
[32m[0328 16:30:53 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.67989
[32m[0328 16:30:53 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 86.789
[32m[0328 16:30:53 @monitor.py:467][0m learning_rate: 0.0099933
[32m[0328 16:30:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 325.37
[32m[0328 16:30:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 129.54
[32m[0328 16:30:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 53.406
[32m[0328 16:30:53 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.6852
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/box_loss: 0.016571
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/label_loss: 0.010173
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0020105
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.0021976
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.76241
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.81055
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.79373
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.82201
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.82195
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.7734
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 2.4149
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 188.55
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0048782
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0043206
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.55428
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.60107
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.66695
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.69492
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.68979
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.67771
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 4.6244
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 47.107
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.0090527
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.0029371
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.8601
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.87353
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.91125
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.91428
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.91263
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.91212
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 10.693
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 18.488
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00062913
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.00060719
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.50479
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.51475
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.56885
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.56942
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.56942
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.56942
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 0.78767
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 1.7616
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_loss: 0.00011008
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49001
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49006
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.49007
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:30:53 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.088182
[32m[0328 16:30:53 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 425.21
[32m[0328 16:30:53 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 86.789
[32m[0328 16:30:53 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.78385
[32m[0328 16:30:53 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:30:53 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 1
[32m[0328 16:30:53 @monitor.py:467][0m total_cost: 0.87646
[32m[0328 16:30:53 @monitor.py:467][0m wd_cost: 0.47003
[32m[0328 16:30:53 @base.py:275][0m Start Epoch 3 ...
[32m[0328 16:31:52 @base.py:285][0m Epoch 3 (global_step 1500) finished, time:58.9 seconds.
[32m[0328 16:31:52 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:31:52 @misc.py:109][0m Estimated Time Left: 3 days 22 hours 32 minutes 49 seconds
[32m[0328 16:31:52 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:31:52 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:31:52 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.15478
[32m[0328 16:31:52 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.15903
[32m[0328 16:31:52 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.94654
[32m[0328 16:31:52 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.13223
[32m[0328 16:31:52 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.83414
[32m[0328 16:31:52 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 107.88
[32m[0328 16:31:52 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:31:52 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 354.67
[32m[0328 16:31:52 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 119.46
[32m[0328 16:31:52 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 35.398
[32m[0328 16:31:52 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 2.4687
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/box_loss: 0.010343
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/label_loss: 0.006918
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0010775
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.0023248
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.56887
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.61541
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.64705
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.71666
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.71547
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.65711
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 1.7234
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 188
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.004709
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0025083
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.57461
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.63442
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.69219
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.76157
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.76154
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.75958
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 7.0915
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 49.243
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.003657
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.0013851
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.72744
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.75291
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.78127
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.7989
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.79887
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.7986
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 7.5643
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 15.551
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00089925
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.00069952
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.48958
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.53582
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.56374
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.58968
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.58968
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.58968
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 2.185
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 3.1777
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_loss: 2.7316e-07
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.5
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.5
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:31:52 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.031377
[32m[0328 16:31:52 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 404.12
[32m[0328 16:31:52 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 107.88
[32m[0328 16:31:52 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.81597
[32m[0328 16:31:52 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:31:52 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 1
[32m[0328 16:31:52 @monitor.py:467][0m total_cost: 0.80071
[32m[0328 16:31:52 @monitor.py:467][0m wd_cost: 0.46964
[32m[0328 16:31:52 @base.py:275][0m Start Epoch 4 ...
[32m[0328 16:32:50 @base.py:285][0m Epoch 4 (global_step 2000) finished, time:58.9 seconds.
[32m[0328 16:32:50 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:32:50 @misc.py:109][0m Estimated Time Left: 3 days 22 hours 23 minutes 54 seconds
[32m[0328 16:32:50 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:32:50 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:32:50 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.13304
[32m[0328 16:32:50 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.14832
[32m[0328 16:32:50 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.94804
[32m[0328 16:32:50 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.13547
[32m[0328 16:32:50 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.85125
[32m[0328 16:32:50 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 112.33
[32m[0328 16:32:50 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:32:50 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 373.29
[32m[0328 16:32:50 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 102.97
[32m[0328 16:32:50 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 33.134
[32m[0328 16:32:50 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 2.6031
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/box_loss: 0.01345
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/label_loss: 0.0083487
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0026741
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.0039286
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.63604
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.65418
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.70718
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.73593
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.73118
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.70848
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 2.8361
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 191.51
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0056278
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0019775
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.67027
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.74114
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.77491
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.79662
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.79662
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.79037
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 6.758
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 46.354
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.0038426
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.0022356
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.68518
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.69774
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.76347
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.80649
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.80642
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.80303
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 7.4032
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 15.247
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.0013054
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.00017273
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.53711
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.58064
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.58103
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.58113
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.58113
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.58113
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 1.6963
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 2.8161
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_loss: 3.4281e-05
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.48492
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.48492
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:32:50 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.067706
[32m[0328 16:32:50 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 399.67
[32m[0328 16:32:50 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 112.33
[32m[0328 16:32:50 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.81721
[32m[0328 16:32:50 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:32:50 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 1
[32m[0328 16:32:50 @monitor.py:467][0m total_cost: 0.77236
[32m[0328 16:32:50 @monitor.py:467][0m wd_cost: 0.4692
[32m[0328 16:32:50 @base.py:275][0m Start Epoch 5 ...
[32m[0328 16:33:48 @base.py:285][0m Epoch 5 (global_step 2500) finished, time:58 seconds.
[32m[0328 16:33:48 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:33:51 @saver.py:79][0m Model saved to models/frcnn/model-2500.
[32m[0328 16:33:51 @misc.py:109][0m Estimated Time Left: 3 days 22 hours 30 minutes 51 seconds
[32m[0328 16:33:51 @eval.py:258][0m Running evaluation ...
[32m[0328 16:34:19 @monitor.py:467][0m AP/": 0
[32m[0328 16:34:19 @monitor.py:467][0m AP/.: 0.19045
[32m[0328 16:34:19 @monitor.py:467][0m AP/0: 0.19639
[32m[0328 16:34:19 @monitor.py:467][0m AP/1: 0.17382
[32m[0328 16:34:19 @monitor.py:467][0m AP/2: 0.18243
[32m[0328 16:34:19 @monitor.py:467][0m AP/3: 0.17844
[32m[0328 16:34:19 @monitor.py:467][0m AP/3$: 0
[32m[0328 16:34:19 @monitor.py:467][0m AP/4: 0.1933
[32m[0328 16:34:19 @monitor.py:467][0m AP/5: 0.23792
[32m[0328 16:34:19 @monitor.py:467][0m AP/6: 0.1764
[32m[0328 16:34:19 @monitor.py:467][0m AP/7: 0.19465
[32m[0328 16:34:19 @monitor.py:467][0m AP/8: 0.21501
[32m[0328 16:34:19 @monitor.py:467][0m AP/9: 0.20985
[32m[0328 16:34:19 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:34:19 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:34:19 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.13492
[32m[0328 16:34:19 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.13339
[32m[0328 16:34:19 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.95381
[32m[0328 16:34:19 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.089746
[32m[0328 16:34:19 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.89948
[32m[0328 16:34:19 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 112.89
[32m[0328 16:34:19 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:34:19 @monitor.py:467][0m mAP: 0.16528
[32m[0328 16:34:19 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 351.5
[32m[0328 16:34:19 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 116.95
[32m[0328 16:34:19 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 40.328
[32m[0328 16:34:19 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.2187
[32m[0328 16:34:19 @monitor.py:467][0m precision/": 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/.: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/0: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/1: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/2: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/3: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/3$: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/4: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/5: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/6: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/7: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/8: 0
[32m[0328 16:34:19 @monitor.py:467][0m precision/9: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/": 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/.: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/0: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/1: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/2: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/3: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/3$: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/4: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/5: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/6: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/7: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/8: 0
[32m[0328 16:34:19 @monitor.py:467][0m recall/9: 0
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/box_loss: 0.011995
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/label_loss: 0.0047054
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0014769
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.0015371
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.63391
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.68839
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.72836
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.73543
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.73523
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.73369
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 2.0238
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 187.46
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0044944
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0014668
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.63763
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.67303
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.69212
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.70373
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.70373
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.69795
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 5.6351
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 47.339
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.0052921
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.0013745
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.77106
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.8003
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.83
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.84952
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.84952
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.84926
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 10.244
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 18.366
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00073169
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.0003212
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.56858
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.58605
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.58866
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.59288
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.59288
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.59288
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 1.7696
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 2.8004
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_loss: 5.8027e-06
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49978
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49978
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.49982
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:34:19 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.038754
[32m[0328 16:34:19 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 399.11
[32m[0328 16:34:19 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 112.89
[32m[0328 16:34:19 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.81706
[32m[0328 16:34:19 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:34:19 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.99875
[32m[0328 16:34:19 @monitor.py:467][0m total_cost: 0.75372
[32m[0328 16:34:19 @monitor.py:467][0m wd_cost: 0.46871
[32m[0328 16:34:19 @group.py:48][0m Callbacks took 30.524 sec in total. EvalCallback: 27.8 seconds
[32m[0328 16:34:19 @base.py:275][0m Start Epoch 6 ...
[32m[0328 16:35:16 @base.py:285][0m Epoch 6 (global_step 3000) finished, time:57 seconds.
[32m[0328 16:35:16 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:35:16 @misc.py:109][0m Estimated Time Left: 3 days 22 hours 29 minutes 52 seconds
[32m[0328 16:35:16 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:35:16 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:35:16 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.10069
[32m[0328 16:35:16 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.10358
[32m[0328 16:35:16 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.96156
[32m[0328 16:35:16 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.069077
[32m[0328 16:35:16 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.9287
[32m[0328 16:35:16 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 117.3
[32m[0328 16:35:16 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:35:16 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 344.78
[32m[0328 16:35:16 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 119.61
[32m[0328 16:35:16 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 44.05
[32m[0328 16:35:16 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 3.564
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/box_loss: 0.011635
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/label_loss: 0.0047795
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0015757
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.00087452
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.67009
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.69378
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.71755
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.7302
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.7302
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.73019
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 2.1402
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 187.44
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0049639
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0026523
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.63623
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.66627
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.69818
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.73923
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.73923
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.73878
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 6.6744
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 48.601
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.004801
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.001172
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.88773
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.89013
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.89402
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.89726
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.89726
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.8965
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 10.07
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 18.374
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00029475
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_loss: 7.9921e-05
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.53229
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.5353
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.53595
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.5362
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.5362
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.5362
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 0.67894
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 1.5269
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_loss: 7.8986e-07
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49998
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49999
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.49999
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:35:16 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.058543
[32m[0328 16:35:16 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 394.7
[32m[0328 16:35:16 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 117.3
[32m[0328 16:35:16 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.81432
[32m[0328 16:35:16 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:35:16 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 1
[32m[0328 16:35:16 @monitor.py:467][0m total_cost: 0.68892
[32m[0328 16:35:16 @monitor.py:467][0m wd_cost: 0.46823
[32m[0328 16:35:16 @base.py:275][0m Start Epoch 7 ...
[32m[0328 16:36:14 @base.py:285][0m Epoch 7 (global_step 3500) finished, time:57.8 seconds.
[32m[0328 16:36:14 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:36:14 @misc.py:109][0m Estimated Time Left: 3 days 22 hours 13 minutes 1 second
[32m[0328 16:36:14 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:36:14 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:36:14 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.1162
[32m[0328 16:36:14 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.11124
[32m[0328 16:36:14 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.96055
[32m[0328 16:36:14 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.088085
[32m[0328 16:36:14 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.90525
[32m[0328 16:36:14 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 114.23
[32m[0328 16:36:14 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:36:14 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 365.73
[32m[0328 16:36:14 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 106.54
[32m[0328 16:36:14 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 37.102
[32m[0328 16:36:14 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 2.6269
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/box_loss: 0.0084923
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/label_loss: 0.0045779
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.00088798
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.00050551
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.68838
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.70588
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.70687
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.70715
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.70714
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.70286
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 1.6012
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 188.54
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0032818
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0013147
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.72501
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.73012
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.74304
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.77905
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.77905
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.77659
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 6.3018
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 48.151
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.003611
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.0024652
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.78876
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.79823
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.84536
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.84701
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.84701
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.8438
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 8.535
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 16.42
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00071144
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.00029214
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.59125
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.593
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.60057
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.60131
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.60131
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.60131
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 1.7593
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 2.8177
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_loss: 3.9844e-07
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49999
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.49999
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:36:14 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.07494
[32m[0328 16:36:14 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 397.77
[32m[0328 16:36:14 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 114.23
[32m[0328 16:36:14 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.819
[32m[0328 16:36:14 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:36:14 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 1
[32m[0328 16:36:14 @monitor.py:467][0m total_cost: 0.70823
[32m[0328 16:36:14 @monitor.py:467][0m wd_cost: 0.46772
[32m[0328 16:36:14 @base.py:275][0m Start Epoch 8 ...
[32m[0328 16:37:11 @base.py:285][0m Epoch 8 (global_step 4000) finished, time:57.5 seconds.
[32m[0328 16:37:11 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:37:11 @misc.py:109][0m Estimated Time Left: 3 days 22 hours 4 minutes 55 seconds
[32m[0328 16:37:11 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:37:11 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:37:11 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.095995
[32m[0328 16:37:11 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.097324
[32m[0328 16:37:11 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.96476
[32m[0328 16:37:11 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.085011
[32m[0328 16:37:11 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.91086
[32m[0328 16:37:11 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 119.34
[32m[0328 16:37:11 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:37:11 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 382.03
[32m[0328 16:37:11 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 92.057
[32m[0328 16:37:11 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 35.727
[32m[0328 16:37:11 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 2.1841
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/box_loss: 0.00818
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/label_loss: 0.0025093
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.00057037
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.00065667
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.62563
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.62661
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.63378
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.65418
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.65418
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.65355
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 1.3197
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 188.04
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0045517
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.0010997
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.75938
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.78275
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.79013
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.79793
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.79793
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.79784
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 7.9751
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 49.388
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.0029291
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.00071656
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.84989
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.85318
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.85428
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.87862
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.87785
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.87708
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 8.7376
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 17.207
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00012883
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_loss: 3.6243e-05
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.51707
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.52881
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.52883
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.52903
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.52903
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.52903
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 0.2665
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 1.3476
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_loss: 1.0394e-07
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.5
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.5
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:37:11 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.019181
[32m[0328 16:37:11 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 392.66
[32m[0328 16:37:11 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 119.34
[32m[0328 16:37:11 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.83721
[32m[0328 16:37:11 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:37:11 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 1
[32m[0328 16:37:11 @monitor.py:467][0m total_cost: 0.67122
[32m[0328 16:37:11 @monitor.py:467][0m wd_cost: 0.46721
[32m[0328 16:37:11 @base.py:275][0m Start Epoch 9 ...
[32m[0328 16:38:09 @base.py:285][0m Epoch 9 (global_step 4500) finished, time:57.9 seconds.
[32m[0328 16:38:09 @graph.py:73][0m Running Op sync_variables/sync_variables_from_main_tower ...
[32m[0328 16:38:09 @misc.py:109][0m Estimated Time Left: 3 days 20 hours 27 minutes 39 seconds
[32m[0328 16:38:09 @monitor.py:467][0m PeakMemory(MB)/gpu:0: 4786.9
[32m[0328 16:38:09 @monitor.py:467][0m QueueInput/queue_size: 50
[32m[0328 16:38:09 @monitor.py:467][0m fastrcnn_losses/box_loss: 0.094598
[32m[0328 16:38:09 @monitor.py:467][0m fastrcnn_losses/label_loss: 0.092678
[32m[0328 16:38:09 @monitor.py:467][0m fastrcnn_losses/label_metrics/accuracy: 0.96439
[32m[0328 16:38:09 @monitor.py:467][0m fastrcnn_losses/label_metrics/false_negative: 0.069345
[32m[0328 16:38:09 @monitor.py:467][0m fastrcnn_losses/label_metrics/fg_accuracy: 0.92949
[32m[0328 16:38:09 @monitor.py:467][0m fastrcnn_losses/num_fg_label: 110.91
[32m[0328 16:38:09 @monitor.py:467][0m learning_rate: 0.01
[32m[0328 16:38:09 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level2: 366.32
[32m[0328 16:38:09 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level3: 104.75
[32m[0328 16:38:09 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level4: 38.407
[32m[0328 16:38:09 @monitor.py:467][0m multilevel_roi_align/fpn_map_rois_to_levels/num_roi_level5: 2.5284
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/box_loss: 0.0086699
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/label_loss: 0.0036537
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/box_loss: 0.0017885
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_loss: 0.0015936
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.1: 0.69807
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.2: 0.7046
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_metrics/precision_th0.5: 0.71972
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.1: 0.74036
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.2: 0.74036
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/label_metrics/recall_th0.5: 0.74036
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/num_pos_anchor: 2.7533
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level2/num_valid_anchor: 189.05
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/box_loss: 0.0032081
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_loss: 0.00098838
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.1: 0.6767
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.2: 0.68982
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_metrics/precision_th0.5: 0.71775
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.1: 0.7323
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.2: 0.7323
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/label_metrics/recall_th0.5: 0.7323
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/num_pos_anchor: 5.8156
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level3/num_valid_anchor: 47.981
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/box_loss: 0.0030412
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_loss: 0.00077183
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.1: 0.7872
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.2: 0.79116
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_metrics/precision_th0.5: 0.81986
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.1: 0.82573
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.2: 0.82573
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/label_metrics/recall_th0.5: 0.82462
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/num_pos_anchor: 8.0015
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level4/num_valid_anchor: 15.713
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/box_loss: 0.00063205
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_loss: 0.0002983
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.1: 0.54047
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.2: 0.54067
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_metrics/precision_th0.5: 0.58489
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.1: 0.5849
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.2: 0.5849
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/label_metrics/recall_th0.5: 0.5849
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/num_pos_anchor: 1.8226
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level5/num_valid_anchor: 3.199
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/box_loss: 0
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_loss: 1.6178e-06
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.1: 0.49995
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.2: 0.5
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_metrics/precision_th0.5: 0.5
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.1: 0.5
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.2: 0.5
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/label_metrics/recall_th0.5: 0.5
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/num_pos_anchor: 0
[32m[0328 16:38:09 @monitor.py:467][0m rpn_losses/level6/num_valid_anchor: 0.057548
[32m[0328 16:38:09 @monitor.py:467][0m sample_fast_rcnn_targets/num_bg: 401.09
[32m[0328 16:38:09 @monitor.py:467][0m sample_fast_rcnn_targets/num_fg: 110.91
[32m[0328 16:38:09 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/best_iou_per_gt: 0.83437
[32m[0328 16:38:09 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.3: 1
[32m[0328 16:38:09 @monitor.py:467][0m sample_fast_rcnn_targets/proposal_metrics/recall_iou0.5: 0.99996
[32m[0328 16:38:09 @monitor.py:467][0m total_cost: 0.6663
[32m[0328 16:38:09 @monitor.py:467][0m wd_cost: 0.4667
[32m[0328 16:38:09 @base.py:275][0m Start Epoch 10 ...
