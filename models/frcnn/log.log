[32m[0328 14:47:46 @logger.py:90][0m Argv: FasterRCNN/train.py
[32m[0328 14:47:47 @train.py:465][0m Environment Information:
--------------------  -----------------------------------------------------------
Python                3.5.3 (default, Sep 27 2018, 17:25:39) [GCC 6.3.0 20170516]
Tensorpack            v0.9.3-2-g2b4ec72e-dirty
TensorFlow            1.13.1/b'v1.13.1-0-g6612da8'
TF Compiler Version   4.8.4
TF CUDA support       True
TF MKL support        False
Nvidia Driver         /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.410.72
CUDA                  /usr/local/cuda-10.0/lib64/libcudart.so.10.0.130
CUDNN                 /usr/local/cuda-10.0/lib64/libcudnn.so.7.4.1
NCCL                  /usr/local/nccl2/lib/libnccl.so.2.3.4
CUDA_VISIBLE_DEVICES  None
GPU 0                 Tesla V100-SXM2-16GB
horovod               0.16.0
cv2                   4.0.0
msgpack               0.6.1
python-prctl          False
--------------------  -----------------------------------------------------------
[32m[0328 14:47:48 @config.py:281][0m Config: ------------------------------------------
{'BACKBONE': {'FREEZE_AFFINE': False,
              'FREEZE_AT': 2,
              'NORM': 'FreezeBN',
              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],
              'STRIDE_1X1': False,
              'TF_PAD_MODE': False,
              'WEIGHTS': 'models/ImageNet-R50-AlignPadding.npz'},
 'CASCADE': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0],
                                  [30.0, 30.0, 15.0, 15.0]],
             'IOUS': [0.5, 0.6, 0.7]},
 'DATA': {'ABSOLUTE_COORD': True,
          'BASEDIR': 'Datasets/',
          'CLASS_NAMES': ['BG', '0', '1', '6', '3', '4', '5', '.', '7', '2', '9', '8', '3$', '"'],
          'DATAFRAME': 'data/frcnn_df.h5',
          'NUM_CATEGORY': 13,
          'NUM_CLASS': 14,
          'TEST': ('test',),
          'TRAIN': ('test', 'val'),
          'VAL': ('test',)},
 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),
         'CASCADE': False,
         'FRCNN_CONV_HEAD_DIM': 256,
         'FRCNN_FC_HEAD_DIM': 1024,
         'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',
         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',
         'NORM': 'None',
         'NUM_CHANNEL': 256,
         'PROPOSAL_MODE': 'Level',
         'RESOLUTION_REQUIREMENT': 32},
 'FRCNN': {'BATCH_PER_IM': 512,
           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],
           'FG_RATIO': 0.25,
           'FG_THRESH': 0.5},
 'MODE_FPN': True,
 'MODE_MASK': False,
 'MRCNN': {'HEAD_DIM': 256},
 'PREPROC': {'MAX_SIZE': 1024.0,
             'PIXEL_MEAN': [123.675, 116.28, 103.53],
             'PIXEL_STD': [58.395, 57.12, 57.375],
             'TEST_SHORT_EDGE_SIZE': 600,
             'TRAIN_SHORT_EDGE_SIZE': [600, 600]},
 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),
         'ANCHOR_SIZES': (32, 64, 128, 256, 512),
         'ANCHOR_STRIDE': 16,
         'BATCH_PER_IM': 256,
         'CROWD_OVERLAP_THRESH': 9.99,
         'FG_RATIO': 0.5,
         'HEAD_DIM': 1024,
         'MIN_SIZE': 0,
         'NEGATIVE_ANCHOR_THRESH': 0.3,
         'NUM_ANCHOR': 15,
         'POSITIVE_ANCHOR_THRESH': 0.7,
         'PROPOSAL_NMS_THRESH': 0.7,
         'TEST_PER_LEVEL_NMS_TOPK': 1000,
         'TEST_POST_NMS_TOPK': 1000,
         'TEST_PRE_NMS_TOPK': 6000,
         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,
         'TRAIN_POST_NMS_TOPK': 2000,
         'TRAIN_PRE_NMS_TOPK': 12000},
 'TEST': {'FRCNN_NMS_THRESH': 0.5,
          'RESULTS_PER_IM': 100,
          'RESULT_SCORE_THRESH': 0.05,
          'RESULT_SCORE_THRESH_VIS': 0.5},
 'TRAIN': {'BASE_LR': 0.01,
           'EVAL_PERIOD': 5,
           'LR_SCHEDULE': [240000, 320000, 360000],
           'NUM_GPUS': 1,
           'STARTING_EPOCH': 1,
           'STEPS_PER_EPOCH': 500,
           'WARMUP': 1000,
           'WARMUP_INIT_LR': 0.0033000000000000004,
           'WEIGHT_DECAY': 0.0001},
 'TRAINER': 'replicated'}
[32m[0328 14:47:48 @train.py:481][0m Warm Up Schedule (steps, value): [(0, 0.0033000000000000004), (1000, 0.01)]
[32m[0328 14:47:48 @train.py:482][0m LR Schedule (epochs, value): [(2, 0.01), (3840.0, 0.001), (5120.0, 0.00010000000000000002)]
[32m[0328 14:47:49 @data.py:50][0m Ground-Truth Boxes:
[36m| class   |   #box |
|:--------|-------:|
| BG      |      0 |
| 0       |    413 |
| 1       |    147 |
| 6       |     61 |
| 3       |     46 |
| 4       |     83 |
| 5       |     48 |
| .       |    117 |
| 7       |     47 |
| 2       |     98 |
| 9       |     42 |
| 8       |     44 |
| 3$      |      0 |
| "       |      1 |
| total   |   1147 |[0m
[32m[0328 14:47:49 @data.py:295][0m Filtered 0 images which contain no non-crowd groudtruth boxes. Total #images for training: 779
[32m[0328 14:47:49 @train.py:486][0m Total passes of the training set is: 3697
[32m[0328 14:47:50 @input_source.py:222][0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[32m[0328 14:47:50 @training.py:110][0m Building graph for training tower 0 on device /gpu:0 ...
[32m[0328 14:47:50 @registry.py:126][0m conv0 input: [1, 3, None, None]
[32m[0328 14:47:50 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m conv0 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m pool0 input: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:134][0m pool0 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block0/conv1 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block0/conv1 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block0/conv2 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block0/conv2 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block0/conv3 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block0/conv3 output: [1, 256, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block0/convshortcut input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block0/convshortcut output: [1, 256, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block1/conv1 input: [1, 256, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block1/conv1 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block1/conv2 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block1/conv2 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block1/conv3 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block1/conv3 output: [1, 256, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block2/conv1 input: [1, 256, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block2/conv1 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block2/conv2 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block2/conv2 output: [1, 64, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group0/block2/conv3 input: [1, 64, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group0/block2/conv3 output: [1, 256, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block0/conv1 input: [1, 256, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block0/conv1 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block0/conv2 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block0/conv2 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block0/conv3 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block0/conv3 output: [1, 512, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block0/convshortcut input: [1, 256, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block0/convshortcut output: [1, 512, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block1/conv1 input: [1, 512, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block1/conv1 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block1/conv2 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block1/conv2 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block1/conv3 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block1/conv3 output: [1, 512, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block2/conv1 input: [1, 512, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block2/conv1 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block2/conv2 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block2/conv2 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block2/conv3 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block2/conv3 output: [1, 512, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block3/conv1 input: [1, 512, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block3/conv1 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block3/conv2 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block3/conv2 output: [1, 128, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group1/block3/conv3 input: [1, 128, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:51 @registry.py:134][0m group1/block3/conv3 output: [1, 512, None, None]
[32m[0328 14:47:51 @registry.py:126][0m group2/block0/conv1 input: [1, 512, None, None]
[32m[0328 14:47:51 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block0/conv1 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block0/conv2 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block0/conv2 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block0/conv3 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block0/conv3 output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block0/convshortcut input: [1, 512, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block0/convshortcut output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block1/conv1 input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block1/conv1 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block1/conv2 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block1/conv2 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block1/conv3 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block1/conv3 output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block2/conv1 input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block2/conv1 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block2/conv2 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block2/conv2 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block2/conv3 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block2/conv3 output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block3/conv1 input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block3/conv1 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block3/conv2 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block3/conv2 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block3/conv3 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block3/conv3 output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block4/conv1 input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block4/conv1 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block4/conv2 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block4/conv2 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block4/conv3 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block4/conv3 output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block5/conv1 input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block5/conv1 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block5/conv2 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block5/conv2 output: [1, 256, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group2/block5/conv3 input: [1, 256, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group2/block5/conv3 output: [1, 1024, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group3/block0/conv1 input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group3/block0/conv1 output: [1, 512, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group3/block0/conv2 input: [1, 512, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group3/block0/conv2 output: [1, 512, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group3/block0/conv3 input: [1, 512, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:52 @registry.py:134][0m group3/block0/conv3 output: [1, 2048, None, None]
[32m[0328 14:47:52 @registry.py:126][0m group3/block0/convshortcut input: [1, 1024, None, None]
[32m[0328 14:47:52 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block0/convshortcut output: [1, 2048, None, None]
[32m[0328 14:47:53 @registry.py:126][0m group3/block1/conv1 input: [1, 2048, None, None]
[32m[0328 14:47:53 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block1/conv1 output: [1, 512, None, None]
[32m[0328 14:47:53 @registry.py:126][0m group3/block1/conv2 input: [1, 512, None, None]
[32m[0328 14:47:53 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block1/conv2 output: [1, 512, None, None]
[32m[0328 14:47:53 @registry.py:126][0m group3/block1/conv3 input: [1, 512, None, None]
[32m[0328 14:47:53 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block1/conv3 output: [1, 2048, None, None]
[32m[0328 14:47:53 @registry.py:126][0m group3/block2/conv1 input: [1, 2048, None, None]
[32m[0328 14:47:53 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block2/conv1 output: [1, 512, None, None]
[32m[0328 14:47:53 @registry.py:126][0m group3/block2/conv2 input: [1, 512, None, None]
[32m[0328 14:47:53 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block2/conv2 output: [1, 512, None, None]
[32m[0328 14:47:53 @registry.py:126][0m group3/block2/conv3 input: [1, 512, None, None]
[32m[0328 14:47:53 @batch_norm.py:177][0m [5m[31mWRN[0m [BatchNorm] Using moving_mean/moving_variance in training.
[32m[0328 14:47:53 @registry.py:134][0m group3/block2/conv3 output: [1, 2048, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn input: [1, 256, None, None],[1, 512, None, None],[1, 1024, None, None],[1, 2048, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/lateral_1x1_c2 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/lateral_1x1_c2 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/lateral_1x1_c3 input: [1, 512, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/lateral_1x1_c3 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/lateral_1x1_c4 input: [1, 1024, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/lateral_1x1_c4 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/lateral_1x1_c5 input: [1, 2048, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/lateral_1x1_c5 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/upsample_lat5 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/upsample_lat5 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/upsample_lat4 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/upsample_lat4 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/upsample_lat3 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/upsample_lat3 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/posthoc_3x3_p2 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/posthoc_3x3_p2 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/posthoc_3x3_p3 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/posthoc_3x3_p3 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/posthoc_3x3_p4 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/posthoc_3x3_p4 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/posthoc_3x3_p5 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/posthoc_3x3_p5 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:126][0m fpn/maxpool_p6 input: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn/maxpool_p6 output: [1, 256, None, None]
[32m[0328 14:47:53 @registry.py:134][0m fpn output: [1, 256, None, None],[1, 256, None, None],[1, 256, None, None],[1, 256, None, None],[1, 256, None, None]
[32m[0328 14:47:54 @registry.py:126][0m rpn input: [1, 256, None, None]
[32m[0328 14:47:54 @registry.py:126][0m rpn/conv0 input: [1, 256, None, None]
[32m[0328 14:47:54 @registry.py:134][0m rpn/conv0 output: [1, 256, None, None]
[32m[0328 14:47:54 @registry.py:126][0m rpn/class input: [1, 256, None, None]
[32m[0328 14:47:54 @registry.py:134][0m rpn/class output: [1, 3, None, None]
[32m[0328 14:47:54 @registry.py:126][0m rpn/box input: [1, 256, None, None]
[32m[0328 14:47:54 @registry.py:134][0m rpn/box output: [1, 12, None, None]
[32m[0328 14:47:54 @registry.py:134][0m rpn output: [None, None, 3],[None, None, 3, 4]
[32m[0328 14:47:57 @registry.py:126][0m fastrcnn input: [None, 256, 7, 7]
[32m[0328 14:47:57 @registry.py:126][0m fastrcnn/fc6 input: [None, 256, 7, 7]
[32m[0328 14:47:57 @registry.py:134][0m fastrcnn/fc6 output: [None, 1024]
[32m[0328 14:47:57 @registry.py:126][0m fastrcnn/fc7 input: [None, 1024]
[32m[0328 14:47:57 @registry.py:134][0m fastrcnn/fc7 output: [None, 1024]
[32m[0328 14:47:57 @registry.py:134][0m fastrcnn output: [None, 1024]
[32m[0328 14:47:57 @registry.py:126][0m fastrcnn/outputs input: [None, 1024]
[32m[0328 14:47:57 @registry.py:126][0m fastrcnn/outputs/class input: [None, 1024]
[32m[0328 14:47:57 @registry.py:134][0m fastrcnn/outputs/class output: [None, 14]
[32m[0328 14:47:57 @registry.py:126][0m fastrcnn/outputs/box input: [None, 1024]
[32m[0328 14:47:57 @registry.py:134][0m fastrcnn/outputs/box output: [None, 56]
[32m[0328 14:47:57 @registry.py:134][0m fastrcnn/outputs output: [None, 14],[None, 14, 4]
[32m[0328 14:47:58 @regularize.py:97][0m regularize_cost() found 57 variables to regularize.
[32m[0328 14:47:58 @regularize.py:21][0m The following tensors will be regularized: group1/block0/conv1/W:0, group1/block0/conv2/W:0, group1/block0/conv3/W:0, group1/block0/convshortcut/W:0, group1/block1/conv1/W:0, group1/block1/conv2/W:0, group1/block1/conv3/W:0, group1/block2/conv1/W:0, group1/block2/conv2/W:0, group1/block2/conv3/W:0, group1/block3/conv1/W:0, group1/block3/conv2/W:0, group1/block3/conv3/W:0, group2/block0/conv1/W:0, group2/block0/conv2/W:0, group2/block0/conv3/W:0, group2/block0/convshortcut/W:0, group2/block1/conv1/W:0, group2/block1/conv2/W:0, group2/block1/conv3/W:0, group2/block2/conv1/W:0, group2/block2/conv2/W:0, group2/block2/conv3/W:0, group2/block3/conv1/W:0, group2/block3/conv2/W:0, group2/block3/conv3/W:0, group2/block4/conv1/W:0, group2/block4/conv2/W:0, group2/block4/conv3/W:0, group2/block5/conv1/W:0, group2/block5/conv2/W:0, group2/block5/conv3/W:0, group3/block0/conv1/W:0, group3/block0/conv2/W:0, group3/block0/conv3/W:0, group3/block0/convshortcut/W:0, group3/block1/conv1/W:0, group3/block1/conv2/W:0, group3/block1/conv3/W:0, group3/block2/conv1/W:0, group3/block2/conv2/W:0, group3/block2/conv3/W:0, fpn/lateral_1x1_c2/W:0, fpn/lateral_1x1_c3/W:0, fpn/lateral_1x1_c4/W:0, fpn/lateral_1x1_c5/W:0, fpn/posthoc_3x3_p2/W:0, fpn/posthoc_3x3_p3/W:0, fpn/posthoc_3x3_p4/W:0, fpn/posthoc_3x3_p5/W:0, rpn/conv0/W:0, rpn/class/W:0, rpn/box/W:0, fastrcnn/fc6/W:0, fastrcnn/fc7/W:0, fastrcnn/outputs/class/W:0, fastrcnn/outputs/box/W:0
[32m[0328 14:48:04 @training.py:348][0m 'sync_variables_from_main_tower' includes 0 operations.
[32m[0328 14:48:04 @model_utils.py:67][0m [36mList of Trainable Variables: 
[0mname                                   shape                 #elements
-------------------------------------  ------------------  -----------
group1/block0/conv1/W:0                [1, 1, 256, 128]          32768
group1/block0/conv1/bn/gamma:0         [128]                       128
group1/block0/conv1/bn/beta:0          [128]                       128
group1/block0/conv2/W:0                [3, 3, 128, 128]         147456
group1/block0/conv2/bn/gamma:0         [128]                       128
group1/block0/conv2/bn/beta:0          [128]                       128
group1/block0/conv3/W:0                [1, 1, 128, 512]          65536
group1/block0/conv3/bn/gamma:0         [512]                       512
group1/block0/conv3/bn/beta:0          [512]                       512
group1/block0/convshortcut/W:0         [1, 1, 256, 512]         131072
group1/block0/convshortcut/bn/gamma:0  [512]                       512
group1/block0/convshortcut/bn/beta:0   [512]                       512
group1/block1/conv1/W:0                [1, 1, 512, 128]          65536
group1/block1/conv1/bn/gamma:0         [128]                       128
group1/block1/conv1/bn/beta:0          [128]                       128
group1/block1/conv2/W:0                [3, 3, 128, 128]         147456
group1/block1/conv2/bn/gamma:0         [128]                       128
group1/block1/conv2/bn/beta:0          [128]                       128
group1/block1/conv3/W:0                [1, 1, 128, 512]          65536
group1/block1/conv3/bn/gamma:0         [512]                       512
group1/block1/conv3/bn/beta:0          [512]                       512
group1/block2/conv1/W:0                [1, 1, 512, 128]          65536
group1/block2/conv1/bn/gamma:0         [128]                       128
group1/block2/conv1/bn/beta:0          [128]                       128
group1/block2/conv2/W:0                [3, 3, 128, 128]         147456
group1/block2/conv2/bn/gamma:0         [128]                       128
group1/block2/conv2/bn/beta:0          [128]                       128
group1/block2/conv3/W:0                [1, 1, 128, 512]          65536
group1/block2/conv3/bn/gamma:0         [512]                       512
group1/block2/conv3/bn/beta:0          [512]                       512
group1/block3/conv1/W:0                [1, 1, 512, 128]          65536
group1/block3/conv1/bn/gamma:0         [128]                       128
group1/block3/conv1/bn/beta:0          [128]                       128
group1/block3/conv2/W:0                [3, 3, 128, 128]         147456
group1/block3/conv2/bn/gamma:0         [128]                       128
group1/block3/conv2/bn/beta:0          [128]                       128
group1/block3/conv3/W:0                [1, 1, 128, 512]          65536
group1/block3/conv3/bn/gamma:0         [512]                       512
group1/block3/conv3/bn/beta:0          [512]                       512
group2/block0/conv1/W:0                [1, 1, 512, 256]         131072
group2/block0/conv1/bn/gamma:0         [256]                       256
group2/block0/conv1/bn/beta:0          [256]                       256
group2/block0/conv2/W:0                [3, 3, 256, 256]         589824
group2/block0/conv2/bn/gamma:0         [256]                       256
group2/block0/conv2/bn/beta:0          [256]                       256
group2/block0/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block0/conv3/bn/gamma:0         [1024]                     1024
group2/block0/conv3/bn/beta:0          [1024]                     1024
group2/block0/convshortcut/W:0         [1, 1, 512, 1024]        524288
group2/block0/convshortcut/bn/gamma:0  [1024]                     1024
group2/block0/convshortcut/bn/beta:0   [1024]                     1024
group2/block1/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block1/conv1/bn/gamma:0         [256]                       256
group2/block1/conv1/bn/beta:0          [256]                       256
group2/block1/conv2/W:0                [3, 3, 256, 256]         589824
group2/block1/conv2/bn/gamma:0         [256]                       256
group2/block1/conv2/bn/beta:0          [256]                       256
group2/block1/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block1/conv3/bn/gamma:0         [1024]                     1024
group2/block1/conv3/bn/beta:0          [1024]                     1024
group2/block2/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block2/conv1/bn/gamma:0         [256]                       256
group2/block2/conv1/bn/beta:0          [256]                       256
group2/block2/conv2/W:0                [3, 3, 256, 256]         589824
group2/block2/conv2/bn/gamma:0         [256]                       256
group2/block2/conv2/bn/beta:0          [256]                       256
group2/block2/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block2/conv3/bn/gamma:0         [1024]                     1024
group2/block2/conv3/bn/beta:0          [1024]                     1024
group2/block3/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block3/conv1/bn/gamma:0         [256]                       256
group2/block3/conv1/bn/beta:0          [256]                       256
group2/block3/conv2/W:0                [3, 3, 256, 256]         589824
group2/block3/conv2/bn/gamma:0         [256]                       256
group2/block3/conv2/bn/beta:0          [256]                       256
group2/block3/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block3/conv3/bn/gamma:0         [1024]                     1024
group2/block3/conv3/bn/beta:0          [1024]                     1024
group2/block4/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block4/conv1/bn/gamma:0         [256]                       256
group2/block4/conv1/bn/beta:0          [256]                       256
group2/block4/conv2/W:0                [3, 3, 256, 256]         589824
group2/block4/conv2/bn/gamma:0         [256]                       256
group2/block4/conv2/bn/beta:0          [256]                       256
group2/block4/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block4/conv3/bn/gamma:0         [1024]                     1024
group2/block4/conv3/bn/beta:0          [1024]                     1024
group2/block5/conv1/W:0                [1, 1, 1024, 256]        262144
group2/block5/conv1/bn/gamma:0         [256]                       256
group2/block5/conv1/bn/beta:0          [256]                       256
group2/block5/conv2/W:0                [3, 3, 256, 256]         589824
group2/block5/conv2/bn/gamma:0         [256]                       256
group2/block5/conv2/bn/beta:0          [256]                       256
group2/block5/conv3/W:0                [1, 1, 256, 1024]        262144
group2/block5/conv3/bn/gamma:0         [1024]                     1024
group2/block5/conv3/bn/beta:0          [1024]                     1024
group3/block0/conv1/W:0                [1, 1, 1024, 512]        524288
group3/block0/conv1/bn/gamma:0         [512]                       512
group3/block0/conv1/bn/beta:0          [512]                       512
group3/block0/conv2/W:0                [3, 3, 512, 512]        2359296
group3/block0/conv2/bn/gamma:0         [512]                       512
group3/block0/conv2/bn/beta:0          [512]                       512
group3/block0/conv3/W:0                [1, 1, 512, 2048]       1048576
group3/block0/conv3/bn/gamma:0         [2048]                     2048
group3/block0/conv3/bn/beta:0          [2048]                     2048
group3/block0/convshortcut/W:0         [1, 1, 1024, 2048]      2097152
group3/block0/convshortcut/bn/gamma:0  [2048]                     2048
group3/block0/convshortcut/bn/beta:0   [2048]                     2048
group3/block1/conv1/W:0                [1, 1, 2048, 512]       1048576
group3/block1/conv1/bn/gamma:0         [512]                       512
group3/block1/conv1/bn/beta:0          [512]                       512
group3/block1/conv2/W:0                [3, 3, 512, 512]        2359296
group3/block1/conv2/bn/gamma:0         [512]                       512
group3/block1/conv2/bn/beta:0          [512]                       512
group3/block1/conv3/W:0                [1, 1, 512, 2048]       1048576
group3/block1/conv3/bn/gamma:0         [2048]                     2048
group3/block1/conv3/bn/beta:0          [2048]                     2048
group3/block2/conv1/W:0                [1, 1, 2048, 512]       1048576
group3/block2/conv1/bn/gamma:0         [512]                       512
group3/block2/conv1/bn/beta:0          [512]                       512
group3/block2/conv2/W:0                [3, 3, 512, 512]        2359296
group3/block2/conv2/bn/gamma:0         [512]                       512
group3/block2/conv2/bn/beta:0          [512]                       512
group3/block2/conv3/W:0                [1, 1, 512, 2048]       1048576
group3/block2/conv3/bn/gamma:0         [2048]                     2048
group3/block2/conv3/bn/beta:0          [2048]                     2048
fpn/lateral_1x1_c2/W:0                 [1, 1, 256, 256]          65536
fpn/lateral_1x1_c2/b:0                 [256]                       256
fpn/lateral_1x1_c3/W:0                 [1, 1, 512, 256]         131072
fpn/lateral_1x1_c3/b:0                 [256]                       256
fpn/lateral_1x1_c4/W:0                 [1, 1, 1024, 256]        262144
fpn/lateral_1x1_c4/b:0                 [256]                       256
fpn/lateral_1x1_c5/W:0                 [1, 1, 2048, 256]        524288
fpn/lateral_1x1_c5/b:0                 [256]                       256
fpn/posthoc_3x3_p2/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p2/b:0                 [256]                       256
fpn/posthoc_3x3_p3/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p3/b:0                 [256]                       256
fpn/posthoc_3x3_p4/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p4/b:0                 [256]                       256
fpn/posthoc_3x3_p5/W:0                 [3, 3, 256, 256]         589824
fpn/posthoc_3x3_p5/b:0                 [256]                       256
rpn/conv0/W:0                          [3, 3, 256, 256]         589824
rpn/conv0/b:0                          [256]                       256
rpn/class/W:0                          [1, 1, 256, 3]              768
rpn/class/b:0                          [3]                           3
rpn/box/W:0                            [1, 1, 256, 12]            3072
rpn/box/b:0                            [12]                         12
fastrcnn/fc6/W:0                       [12544, 1024]          12845056
fastrcnn/fc6/b:0                       [1024]                     1024
fastrcnn/fc7/W:0                       [1024, 1024]            1048576
fastrcnn/fc7/b:0                       [1024]                     1024
fastrcnn/outputs/class/W:0             [1024, 14]                14336
fastrcnn/outputs/class/b:0             [14]                         14
fastrcnn/outputs/box/W:0               [1024, 56]                57344
fastrcnn/outputs/box/b:0               [56]                         56[36m
Number of trainable variables: 156
Number of parameters (elements): 41188437
Storage space needed for all trainable variables: 157.12MB[0m
[32m[0328 14:48:04 @base.py:209][0m Setup callbacks graph ...
[32m[0328 14:48:04 @argtools.py:146][0m [5m[31mWRN[0m "import prctl" failed! Install python-prctl so that processes can be cleaned with guarantee.
